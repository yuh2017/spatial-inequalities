{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disasterNumber            4212\n",
      "fyDeclared                2015\n",
      "disasterType                DR\n",
      "incidentType      Severe Storm\n",
      "duration                   3.0\n",
      "incidentdate            201501\n",
      "Name: 8, dtype: object\n",
      "(3438, 6)\n",
      "(56231, 20)\n",
      "State Name                               ALABAMA\n",
      "County Name                              Autauga\n",
      "County FIPS                              '01001'\n",
      "Hazard                            Winter Weather\n",
      "Year                                        1962\n",
      "Month                                         12\n",
      "CropDmg                                  7462.69\n",
      "CropDmg(ADJ 2021)                       65047.63\n",
      "CropDmgPerCapita(ADJ 2021)               1.47293\n",
      "PropertyDmg                              7462.69\n",
      "PropertyDmg(ADJ 2021)                   65047.63\n",
      "PropertyDmgPerCapita(ADJ 2021)           1.47293\n",
      "Injuries                                     0.0\n",
      "InjuriesPerCapita                            0.0\n",
      "Fatalities                                  0.04\n",
      "FatalitiesPerCapita                          0.0\n",
      "Duration_Days                                4.0\n",
      "Fatalities_Duration                          4.0\n",
      "Injuries_Duration                            0.0\n",
      "Property_Damage_Duration                     4.0\n",
      "Crop_Damage_Duration                         4.0\n",
      "Records                                        1\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################################################################################\n",
    "#HMA_pth  = r\"/Users/yuhan/Desktop/paper——revision/FLCounty_JEPR/HazardMitigationGrant/HazardMitigationAssistanceMitigatedProperties1.csv\"\n",
    "disaster_pth  = r\"/Users/yuhan/Desktop/paper——revision/FLCounty_JEPR/HazardMitigationGrant/DisasterDeclarationsSummaries.csv\"\n",
    "DisasterData = pd.read_csv( disaster_pth )\n",
    "#print( DisasterData.loc[2] )\n",
    "\n",
    "#HazardMitigationAssistanceProjectsByNfipCrsCommunities.csv\n",
    "# #MitigationProjectsFL = ProjectData.loc[ProjectData[\"state\"] == \"Florida\"].reset_index()\n",
    "# MitigationProjects1 = ProjectData\n",
    "DisasterData = DisasterData.loc[DisasterData[\"incidentType\"].isin( ['Severe Storm', 'Tropical Storm', \n",
    "                                                             'Hurricane', 'Winter Storm', 'Severe Ice Storm', \n",
    "                                                             'Typhoon', 'Tornado', 'Fire', 'Flood', 'Snowstorm', \n",
    "                                                             'Other',  'Earthquake', 'Volcanic Eruption', \n",
    "                                                             'Drought', 'Dam/Levee Break', 'Freezing', 'Coastal Storm', \n",
    "                                                             'Mud/Landslide', 'Tsunami']  )].reset_index()\n",
    "\n",
    "DeclaredDisasters = DisasterData.loc[ :,[\"disasterNumber\", \"fyDeclared\",\n",
    "                                    \"disasterType\", \"incidentType\", \"incidentBeginDate\",\n",
    "                                    \"incidentEndDate\", \"declaredCountyArea\" ]]\n",
    "\n",
    "DeclaredDisasters = DeclaredDisasters.drop_duplicates()\n",
    "\n",
    "DeclaredDisasters[\"incidentBeginDate\"]  = pd.to_datetime( DeclaredDisasters[\"incidentBeginDate\"], errors = \"coerce\" )\n",
    "DeclaredDisasters[\"incidentEndDate\"]    = pd.to_datetime( DeclaredDisasters[\"incidentEndDate\"], errors = \"coerce\" )\n",
    "DeclaredDisasters[\"duration\"]           = np.abs( (DeclaredDisasters[\"incidentEndDate\"] - \n",
    "                                                    DeclaredDisasters[\"incidentBeginDate\"]).dt.total_seconds() / 60 / 60 / 24 ) + 1\n",
    "\n",
    "DeclaredDisasters[\"BeginQuarter\"]  = (DeclaredDisasters[\"incidentBeginDate\"].dt.month-1)//2 + 1\n",
    "\n",
    "DeclaredDisasters[\"incidentdate\"]       =  DeclaredDisasters[\"incidentBeginDate\"].dt.year.astype(str).str.zfill(4) \\\n",
    "                                            + DeclaredDisasters[\"incidentBeginDate\"].dt.month.astype(str).str.zfill(2)\n",
    "\n",
    "DeclaredDisasters['disasterNumber']     =  DeclaredDisasters['disasterNumber'].astype(\"int64\")\n",
    "\n",
    "\n",
    "DeclaredDisasters = DeclaredDisasters.loc[ DeclaredDisasters[\"fyDeclared\"] > 1988 ]\n",
    "DeclaredDisasters = DeclaredDisasters.loc[ :,[\"disasterNumber\", \"fyDeclared\",\n",
    "                                              \"disasterType\", \"incidentType\", \n",
    "                                              \"duration\", \"incidentdate\" ]].drop_duplicates()\n",
    "\n",
    "DeclaredDisasters = DeclaredDisasters.drop_duplicates()\n",
    "\n",
    "\n",
    "print( DeclaredDisasters.iloc[1] )\n",
    "print( DeclaredDisasters.shape )\n",
    "print( DisasterData.shape )\n",
    "\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "sheldus_pth  = r\"/Users/yuhan/Desktop/paper——revision/UID10427_ZIP_2/UID10427f_AGG_A_month.csv\"\n",
    "SheldusData = pd.read_csv( sheldus_pth )\n",
    "print( SheldusData.iloc[2] )\n",
    "SheldusData = SheldusData.loc[ SheldusData[\"Year\"] > 1988 ]\n",
    "SheldusData[\"County FIPS\"]      =  SheldusData[\"County FIPS\"].str.strip(\"'\")\n",
    "\n",
    "SheldusData[\"Quarter\"]          = (SheldusData[\"Month\"]-1)//2 + 1\n",
    "\n",
    "#SheldusData[\"incidentdate\"]     =  SheldusData[\"Year\"].astype(str).str.zfill(4) \\\n",
    "#                                + SheldusData[\"Month\"].astype(str).str.zfill(2) \n",
    "\n",
    "SheldusData[\"sheldusdateplace\"] =  SheldusData[\"Year\"].astype(str).str.zfill(4) \\\n",
    "                                + SheldusData[\"Month\"].astype(str).str.zfill(2) \\\n",
    "                                + SheldusData[\"County FIPS\"]\n",
    "\n",
    "\n",
    "#wrong\n",
    "#SheldusDeclaredDisasters = pd.merge( SheldusData, DeclaredDisasters ,\n",
    "#                   left_on=['incidentdate'], right_on=['incidentdate'], how='left')\n",
    "\n",
    "\n",
    "DeclaredDisasters.to_csv(r\"/Users/yuhan/Desktop/paper——revision/DeclaredDisasters.csv\", index=False)\n",
    "SheldusData.to_csv(r\"/Users/yuhan/Desktop/paper——revision/SheldusData_add.csv\", index=False)\n",
    "\n",
    "#wrong again\n",
    "#SheldusDeclaredDisasters.to_csv(r\"/Users/yuhan/Desktop/paper——revision/SheldusDeclaredDisasters.csv\", index=False)\n",
    "\n",
    "####################################################################################################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hazard2\n",
      "Wind                              153100\n",
      "Severe Storm/Hurricane/Tornado    145360\n",
      "Winter Weather                     66379\n",
      "Flooding                           52851\n",
      "Severe/Thunder Storm               17415\n",
      "Drought/Heat                       11385\n",
      "Wildfire                            2904\n",
      "Other Hazard                        1947\n",
      "Earthquake/Volcano/Landslide        1286\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def label_hazard(row):\n",
    "\n",
    "   if 'Severe Storm/Thunder Storm' in row['Hazard' ]  :\n",
    "      return 'Severe Storm/Hurricane/Tornado'\n",
    "   if 'Flooding' in row['Hazard' ] :\n",
    "      return 'Flooding'\n",
    "   if 'Drought' in row['Hazard' ] :\n",
    "      return 'Drought/Heat'\n",
    "   if 'Wind' in row['Hazard' ]:\n",
    "      return 'Wind'\n",
    "   if 'Winter Weather' in row['Hazard' ] :\n",
    "      return 'Winter Weather'\n",
    "   if 'Coastal' in row['Hazard' ]:\n",
    "      return 'Severe Storm/Hurricane/Tornado'\n",
    "   if 'Hurricane/Tropical Storm' in row['Hazard' ] :\n",
    "      return 'Severe Storm/Hurricane/Tornado'\n",
    "   if 'Lightning' in row['Hazard' ]:\n",
    "      return 'Severe/Thunder Storm'\n",
    "   if 'Hail' in row['Hazard' ]:\n",
    "      return 'Winter Weather'\n",
    "   if 'Tornado' in row['Hazard' ] :\n",
    "      return 'Severe Storm/Hurricane/Tornado'\n",
    "   if 'Wildfire' in row['Hazard' ] :\n",
    "      return 'Wildfire'\n",
    "   if 'Earthquake' in row['Hazard' ]:\n",
    "      return 'Earthquake/Volcano/Landslide'\n",
    "   if 'Volcano' in row['Hazard' ] :\n",
    "      return 'Earthquake/Volcano/Landslide'\n",
    "   if 'Heat' in row['Hazard' ]:\n",
    "      return 'Drought/Heat'\n",
    "   if 'Landslide' in row['Hazard' ] :\n",
    "      return 'Earthquake/Volcano/Landslide'\n",
    "   return 'Other Hazard'\n",
    "\n",
    "\n",
    "SheldusData[ 'Hazard2' ] = SheldusData.apply (lambda row: label_hazard(row), axis=1)\n",
    "\n",
    "\n",
    "print( SheldusData[ 'Hazard2' ].value_counts() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "HMA_pth2 =  r\"/Users/yuhan/Desktop/paper——revision/FLCounty_JEPR/HazardMitigationGrant/HazardMitigationAssistanceProjects_new.csv\"\n",
    "HMAData2 = pd.read_csv( HMA_pth2 )\n",
    "\n",
    "HMAData2[\"dateApproved\"]    = pd.to_datetime( HMAData2[\"dateApproved\"], errors = \"coerce\" )\n",
    "HMAData2[\"ApprovedYear\"]    = HMAData2[\"dateApproved\"].dt.year\n",
    "\n",
    "HMAData2['dateClosed'].fillna( pd.to_datetime(\"today\"), inplace=True )\n",
    "HMAData2[\"dateClosed\"]      = pd.to_datetime( HMAData2[\"dateClosed\"], errors = \"coerce\" )\n",
    "HMAData2[\"duration_years\"]  = np.abs( (HMAData2[\"dateClosed\"] - \n",
    "                                        HMAData2[\"dateApproved\"]).dt.total_seconds() / 60 / 60 / 24/ 365 )\n",
    "\n",
    "HMAData2['stateCode']       =  HMAData2['stateNumberCode'].astype(str).str.zfill(2)\n",
    "HMAData2['countyCode']      =  HMAData2['countyCode'].fillna(0).astype(int).astype(str).str.zfill(3)\n",
    "HMAData2['FIPS']            =  HMAData2['stateCode']  + HMAData2['countyCode']\n",
    "\n",
    "HMAData2.loc[ ( HMAData2['countyCode'] == '000' )&\n",
    "              ( HMAData2['recipient']  == 'Statewide' ) ]\n",
    "\n",
    "#HMAData3 = HMAData2.dropna( subset=['duration_years', 'countyCode', 'disasterNumber'] )\n",
    "HMAData3 = HMAData2\n",
    "\n",
    "HMAData3['stateNumberCode'] = HMAData3['stateNumberCode'].apply(int).apply(str)\n",
    "HMAData3['countyCode']      = HMAData3['countyCode'].apply(int).apply(str)\n",
    "HMAData3['FIPS']            = HMAData3['stateNumberCode'].str.zfill(2) + HMAData3['countyCode'].str.zfill(3)\n",
    "\n",
    "HMAData3['disasterNumber']  = HMAData3['disasterNumber'].fillna(0).astype(\"int64\")\n",
    "#pd.to_numeric( HMAData3['disasterNumber'] , errors='coerce').astype(\"int64\")\n",
    "\n",
    "\n",
    "new_df3 = pd.merge(HMAData3, DeclaredDisasters, left_on=['disasterNumber'], \n",
    "                   right_on=['disasterNumber'], how='outer')\n",
    "\n",
    "new_df3[\"incidentdateplace\"] = new_df3[\"incidentdate\"] + new_df3['FIPS']\n",
    "\n",
    "\n",
    "#########################################################################################################################\n",
    "#########################################################################################################################\n",
    "new_df4 = new_df3.loc[ new_df3[\"countyCode\"] != \"0\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['State Name', 'County Name', 'County FIPS', 'Hazard', 'Year', 'Month',\n",
       "       'CropDmg', 'CropDmg(ADJ 2021)', 'CropDmgPerCapita(ADJ 2021)',\n",
       "       'PropertyDmg', 'PropertyDmg(ADJ 2021)',\n",
       "       'PropertyDmgPerCapita(ADJ 2021)', 'Injuries', 'InjuriesPerCapita',\n",
       "       'Fatalities', 'FatalitiesPerCapita', 'Duration_Days',\n",
       "       'Fatalities_Duration', 'Injuries_Duration', 'Property_Damage_Duration',\n",
       "       'Crop_Damage_Duration', 'Records', 'Quarter', 'sheldusdateplace'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SheldusData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuhan/opt/anaconda3/envs/hazard_env/lib/python3.11/site-packages/pyproj/crs/crs.py:141: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "socialattr_pth = r\"/Users/yuhan/Desktop/paper——revision/FLCounty_JEPR/ACS_County_2000_2019_JPER/National Risk Index/NRI_Shapefile_Counties/NRI_Shapefile_Counties.shp\"\n",
    "socialattrreader = gpd.read_file( socialattr_pth )\n",
    "socialattrreader = socialattrreader.to_crs({'init':'epsg:4326'})\n",
    "socialattrreader = socialattrreader[~socialattrreader[\"STATE\"].isin(['Hawaii','Alaska', 'American Samoa', 'Guam', \n",
    "                                                                          'Puerto Rico', 'Virgin Islands',\n",
    "                                                                          'Northern Mariana Islands'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State Name</th>\n",
       "      <th>County Name</th>\n",
       "      <th>County FIPS</th>\n",
       "      <th>Hazard2</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>01001</td>\n",
       "      <td>Severe Storm/Hurricane/Tornado</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>01001</td>\n",
       "      <td>Wind</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>01001</td>\n",
       "      <td>Winter Weather</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>01001</td>\n",
       "      <td>Flooding</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>01001</td>\n",
       "      <td>Severe/Thunder Storm</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State Name County Name County FIPS                         Hazard2  count\n",
       "0    ALABAMA     Autauga       01001  Severe Storm/Hurricane/Tornado     80\n",
       "1    ALABAMA     Autauga       01001                            Wind     65\n",
       "2    ALABAMA     Autauga       01001                  Winter Weather     17\n",
       "3    ALABAMA     Autauga       01001                        Flooding     14\n",
       "4    ALABAMA     Autauga       01001            Severe/Thunder Storm      6"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "SheldusData_agg = SheldusData.groupby(['State Name', \n",
    "                                       'County Name', \n",
    "                                       'County FIPS' ]).Hazard2.value_counts().reset_index()\n",
    "\n",
    "SheldusData_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  State Name County Name   FIPS  Drought/Heat  Earthquake/Volcano/Landslide  \\\n",
      "0    ALABAMA     Autauga  01001           3.0                           0.0   \n",
      "1    ALABAMA     Baldwin  01003           4.0                           0.0   \n",
      "2    ALABAMA     Barbour  01005           2.0                           0.0   \n",
      "3    ALABAMA        Bibb  01007           2.0                           0.0   \n",
      "4    ALABAMA      Blount  01009           2.0                           0.0   \n",
      "\n",
      "   Flooding  Other Hazard  Severe Storm/Hurricane/Tornado  \\\n",
      "0      14.0           0.0                            80.0   \n",
      "1      29.0           3.0                           171.0   \n",
      "2       6.0           0.0                            45.0   \n",
      "3      10.0           0.0                            57.0   \n",
      "4      19.0           0.0                            91.0   \n",
      "\n",
      "   Severe/Thunder Storm  Wildfire  Winter Weather  Wind  \n",
      "0                   6.0       0.0            65.0  17.0  \n",
      "1                  31.0       0.0           102.0  10.0  \n",
      "2                   3.0       0.0            35.0  16.0  \n",
      "3                   1.0       0.0            47.0  15.0  \n",
      "4                   9.0       0.0            79.0  24.0  \n",
      "(3257, 12)\n",
      "Index(['State Name', 'County Name', 'FIPS', 'Drought/Heat',\n",
      "       'Earthquake/Volcano/Landslide', 'Flooding', 'Other Hazard',\n",
      "       'Severe Storm/Hurricane/Tornado', 'Severe/Thunder Storm', 'Wildfire',\n",
      "       'Winter Weather', 'Wind', 'Max'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print( SheldusData_agg.Hazard2.value_counts() )\n",
    "\n",
    "SheldusData_agg2 = SheldusData_agg.pivot_table(index=['State Name', 'County Name', 'County FIPS'], \n",
    "                            values =['count'],  columns=['Hazard2'] )\n",
    "\n",
    "SheldusData_agg2.columns = SheldusData_agg2.columns.droplevel(0)\n",
    "SheldusData_agg2 = SheldusData_agg2.reset_index()\n",
    "\n",
    "SheldusData_agg2.columns = ['State Name', 'County Name', 'FIPS', \n",
    "                            'Drought/Heat', 'Earthquake/Volcano/Landslide', 'Flooding',\n",
    "                               'Other Hazard', 'Severe Storm/Hurricane/Tornado', 'Severe/Thunder Storm',\n",
    "                                   'Wildfire', 'Winter Weather', 'Wind']\n",
    "SheldusData_agg2 = SheldusData_agg2.fillna(0)\n",
    "print( SheldusData_agg2.head() )\n",
    "\n",
    "print( SheldusData_agg2.shape )\n",
    "\n",
    "SheldusData_agg2['Max'] = SheldusData_agg2[ [ 'Drought/Heat', 'Earthquake/Volcano/Landslide', \n",
    "                                             'Flooding', 'Other Hazard', \n",
    "                                             'Severe Storm/Hurricane/Tornado', \n",
    "                                             'Severe/Thunder Storm', 'Wildfire', \n",
    "                                             'Winter Weather', 'Wind' ] ].idxmax(axis=1)\n",
    "\n",
    "print(SheldusData_agg2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "socialattrreader['fips']    = socialattrreader['fips'].astype(str).apply(int)\n",
    "SheldusData_agg2['fips']    = SheldusData_agg2['FIPS'].astype(str).apply(int) \n",
    "\n",
    "socialattrreader = socialattrreader[ ['STATE', 'STATEABBRV', 'COUNTY', 'COUNTYTYPE', \n",
    "                   'fips', 'POPULATION', 'BUILDVALUE', 'AGRIVALUE',\n",
    "                   'RISK_VALUE', 'SOVI_SCORE', 'RESL_VALUE', 'geometry'\n",
    "                   ] ]\n",
    "#print(  SheldusData_agg[\"Hazard2\"].idxmax(axis=1))\n",
    "\n",
    "#SheldusData_agg.to_csv(r\"/Users/yuhan/Desktop/SheldusData_agg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_joini = pd.merge( socialattrreader, SheldusData_agg2, left_on=['fips'], right_on=['fips'], how='left')\n",
    "gdfjoined2 = gpd.GeoDataFrame( df_joini, geometry = 'geometry', crs=\"EPSG:4326\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/8gnslc_j433220_1kgd9hv_c0000gn/T/ipykernel_38948/27691653.py:1: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gdfjoined2.to_file(r\"/Users/yuhan/Desktop/paper——revision/export_results/hazard_aggfips.shp\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gdfjoined2.to_file(r\"/Users/yuhan/Desktop/paper——revision/export_results/hazard_aggfips.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "# SheldusData[['Hazard', 'sheldusdateplace']].groupby(['sheldusdateplace'])['Hazard'].transform(lambda x: ','.join(x))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SheldusData_agg = SheldusData.groupby([ 'State Name', 'County Name', 'County FIPS',  \n",
    "                                       'Year', 'Month', 'sheldusdateplace' ]).agg({\n",
    "                    'Hazard'                            :  ', '.join ,\n",
    "                    'CropDmg'                           :  ['sum'], \n",
    "                    'CropDmg(ADJ 2021)'                 :  ['sum'],\n",
    "                    'CropDmgPerCapita(ADJ 2021)'        :  ['sum'],\n",
    "                    'PropertyDmg'                       :  ['sum'],\n",
    "                    'PropertyDmg(ADJ 2021)'             :  ['sum'],\n",
    "                    'PropertyDmgPerCapita(ADJ 2021)'    :  ['sum'],\n",
    "                    'Injuries'                          :  ['sum'],\n",
    "                    'InjuriesPerCapita'                 :  ['sum'],\n",
    "                    'Fatalities'                        :  ['sum'],\n",
    "                    'FatalitiesPerCapita'               :  ['sum'],\n",
    "                    'Duration_Days'                     :  ['max'],\n",
    "                    'Fatalities_Duration'               :  ['max'],\n",
    "                    'Injuries_Duration'                 :  ['max'],\n",
    "                    'Property_Damage_Duration'          :  ['max'],\n",
    "                    'Crop_Damage_Duration'              :  ['max']  }).reset_index()\n",
    "\n",
    "\n",
    "#SheldusData_agg.to_csv(r\"/Users/yuhan/Desktop/paper——revision/SheldusData_agg.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "SheldusData_agg.columns = SheldusData_agg.columns.droplevel(1)\n",
    "#SheldusData_agg.to_csv(r\"/Users/yuhan/Desktop/paper——revision/SheldusData_agg.csv\", index=False)\n",
    "#print(new_df4.columns)\n",
    "\n",
    "AggregateData4 = pd.merge( SheldusData_agg, new_df4, \n",
    "                         right_on =['incidentdateplace'], left_on =['sheldusdateplace'], how='left')\n",
    "AggregateData4.to_csv(r\"/Users/yuhan/Desktop/paper——revision/HMAData4.csv\", index=False)\n",
    "#(273545, 19) (27035, 41)\n",
    "\n",
    "AggregateData4.shape\n",
    "print( len(new_df4.incidentdateplace.unique()) )\n",
    "print( len(SheldusData_agg.sheldusdateplace.unique()) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281322, 64)\n",
      "(273545, 22)\n"
     ]
    }
   ],
   "source": [
    "print( AggregateData4.loc[ (AggregateData4[\"Year\"] >= 1989) & \n",
    "                                   (AggregateData4[\"programArea\"] != \"PDM\")].reset_index().shape )\n",
    "\n",
    "print( SheldusData_agg.shape )\n",
    "#print( new_df4.loc[ new_df4['Year'] > 1989 ].shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################\n",
    "MitigationProjects2 = new_df4.loc[ (new_df4[\"programFy\"] >= 1989) & \n",
    "                                   (new_df4[\"programArea\"] == \"PDM\")].reset_index()\n",
    "MitigationProjects3 = AggregateData4.loc[ (AggregateData4[\"Year\"] >= 1989) & \n",
    "                                   (AggregateData4[\"programArea\"] != \"PDM\")].reset_index()\n",
    "\n",
    "\n",
    "MitigationProjects2.to_csv(r\"/Users/yuhan/Desktop/paper——revision/HMA_PMD.csv\", index=False)\n",
    "MitigationProjects3.to_csv(r\"/Users/yuhan/Desktop/paper——revision/HMA_nPMD.csv\", index=False)\n",
    "\n",
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hazard_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
